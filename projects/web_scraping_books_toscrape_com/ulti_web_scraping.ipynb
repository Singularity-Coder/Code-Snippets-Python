{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "789ee582-4e9b-463e-8794-014269b2a5f7",
   "metadata": {},
   "source": [
    "# Web Scraping\n",
    "\n",
    "Web scraping for academic or personal use as per AI:\n",
    "\n",
    "1. Wikipedia\n",
    "2. Books To Scrape (https://books.toscrape.com/)\n",
    "3. Quotes To Scrape (https://quotes.toscrape.com/)\n",
    "4. Scrape This Site (http://www.scrapethissite.com/)\n",
    "5. IMDb (with restrictions)\n",
    "6. GitHub (public repositories)\n",
    "7. Data.gov\n",
    "8. Craigslist (with limitations)\n",
    "9. Amazon product listings (with restrictions)\n",
    "10. The New York Times Developer Network (with API key)\n",
    "11. OpenStreetMap\n",
    "12. Goodreads (with API)\n",
    "13. National Weather Service\n",
    "1. **Common Crawl** - A public repository of web crawl data that can be freely accessed and used.\n",
    "2. **Wikipedia** - The content is freely available under a Creative Commons license, and scraping is allowed within certain guidelines.\n",
    "3. **OpenWeatherMap** - Provides weather data, and they offer a free tier API which you can scrape with permission.\n",
    "4. **Reddit** - Allows scraping for non-commercial purposes as long as it abides by their API usage policy.\n",
    "5. **Twitter** - Permits scraping through their API for personal use, subject to rate limits.\n",
    "6. **IMDB** - Has a public dataset available for scraping for non-commercial use.\n",
    "7. **GitHub** - Public repositories can be scraped, but there are rate limits and terms of service to consider.\n",
    "8. **News websites with public APIs** - Such as The Guardian and The New York Times, often provide APIs for accessing their data.\n",
    "\n",
    "Before scraping any website:\n",
    "\n",
    "1. Checking the site's robots.txt file\n",
    "2. Reviewing their terms of service\n",
    "3. Using APIs when available\n",
    "4. Respecting rate limits and not overloading servers\n",
    "5. Identifying your scraper in the user-agent string\n",
    "6. Avoid scraping login-protected content or data behind paywalls without permission.\n",
    "7. For academic or research purposes, contacting the website administrators to seek explicit permission is also advisable.\n",
    "\n",
    "Refer\n",
    "* https://en.wikipedia.org/robots.txt\n",
    "* [Google Scholer](https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=web+scraping+python&btnG=&oq=web+scraping)\n",
    "\n",
    "Overview\n",
    "* Understanding HTML\n",
    "* Extracting Web Content\n",
    "* Extracting all books from a page\n",
    "* Extracting data of a single book\n",
    "* Fetching the data of all books in one page\n",
    "* Scraping all books from all the pages\n",
    "* Fixing the data formatting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dc33bd-7bc8-49c6-b7d5-614138f9a659",
   "metadata": {},
   "source": [
    "### Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "11514453-98c5-4a31-aae4-a14056c0b84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs # can fetch data from html tags\n",
    "from urllib.parse import urljoin\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e9d50b-d0b9-44bf-8762-78b40c097326",
   "metadata": {},
   "source": [
    "### Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f19f0710-b140-4c8c-b670-7501d00aad23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The Great Gatsby', 'To Kill a Mockingbird', '1984', 'The Testaments', 'Normal People']\n"
     ]
    }
   ],
   "source": [
    "html_doc = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <title>Book Store</title>\n",
    "</head>\n",
    "<body>\n",
    "    <div id=\"bestsellers\">\n",
    "        <h2>Best Selling Books</h2>\n",
    "        <ul>\n",
    "            <li><a href=\"/book1\">The Great Gatsby</a></li>\n",
    "            <li><a href=\"/book2\">To Kill a Mockingbird</a></li>\n",
    "            <li><a href=\"/book3\">1984</a></li>\n",
    "        </ul>\n",
    "    </div>\n",
    "    <div id=\"new-releases\">\n",
    "        <h2>New Releases</h2>\n",
    "        <ul>\n",
    "            <li><a href=\"/book4\">The Testaments</a></li>\n",
    "            <li><a href=\"/book5\">Normal People</a></li>\n",
    "        </ul>\n",
    "    </div>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "soup = bs(html_doc, 'html.parser')\n",
    "titles = [a.get_text() for a in soup.find_all('a')]\n",
    "print(titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93be360c-82f2-4866-a0a3-c15979979307",
   "metadata": {},
   "source": [
    "### Get website data\n",
    "1. **200 OK**: The request has been successfully processed, and the server returns the requested content.\n",
    "2. **404 Not Found**: The requested resource or page could not be found on the server.\n",
    "3. **403 Forbidden**: Access to the requested resource is forbidden or not allowed for the client.\n",
    "4. **500 Internal Server Error**: The server encountered an unexpected error while processing the request.\n",
    "5. **302 Found (or 301 Moved Permanently)**: The requested resource has been temporarily (or permanently) moved to a different URL, and the client should follow the redirection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "abbb47b0-7a1c-4617-9678-89bd9d6953ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "url = \"https://books.toscrape.com/\"\n",
    "base_url = \"https://books.toscrape.com/index.html\"\n",
    "book_list = requests.get(base_url)\n",
    "if result.status_code == 200:\n",
    "    print(\"Success\")\n",
    "else:\n",
    "    print(f\"Failed: {book_list.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bedc7a2-580d-4816-b8d8-397fd0371267",
   "metadata": {},
   "source": [
    "### Verify received data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "77a5bb97-a9b9-496a-adda-7e476ad092c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<!--[if lt IE 7]>      <html lang=\"en-us\" class=\"no-js lt-ie9 lt-ie8 lt-ie7\"> <![endif]-->\n",
      "<!--[if IE 7]>         <html lang=\"en-us\" class=\"no-js lt-ie9 lt-ie8\"> <![endif]-->\n",
      "<!--[if IE 8]>         <html lang=\"en-us\" class=\"no-js lt-ie9\"> <![endif]-->\n",
      "<!--[if gt IE 8]><!-->\n",
      "<html class=\"no-js\" lang=\"en-us\">\n",
      " <!--<![endif]-->\n",
      " <head>\n",
      "  <title>\n",
      "   All products | Books to Scrape - Sandbox\n",
      "  </title>\n",
      "  &lt;meta http-equiv=\"content-type\" content=\"text/html; charset=UTF-8\" /\n",
      " </head>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(bs(book_list.content[:500], 'html.parser').prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3f0981-bf1e-4ca6-a313-779634db39e7",
   "metadata": {},
   "source": [
    "### Parse received data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "26e9bc10-214a-4df7-8362-02fb2ad89510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "dc9273cf-cd83-42dd-b292-ef5e63ae60bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This crawls the html page we downloaded\n",
    "# pass parser = \"html.parser\" if allowed & necessary\n",
    "soup = bs(\n",
    "    markup = book_list.content\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "677e2d1f-37d2-4ade-ae19-c7b5d38bfef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "<li class=\"col-xs-6 col-sm-4 col-md-3 col-lg-3\">\n",
      "<article class=\"product_pod\">\n",
      "<div class=\"image_container\">\n",
      "<a href=\"catalogue/tipping-the-velvet_999/index.html\"><img alt=\"Tipping the Velvet\" class=\"thumbnail\" src=\"media/cache/26/0c/260c6ae16bce31c8f8c95daddd9f4a1c.jpg\"/></a>\n",
      "</div>\n",
      "<p class=\"star-rating One\">\n",
      "<i class=\"icon-star\"></i>\n",
      "<i class=\"icon-star\"></i>\n",
      "<i class=\"icon-star\"></i>\n",
      "<i class=\"icon-star\"></i>\n",
      "<i class=\"icon-star\"></i>\n",
      "</p>\n",
      "<h3><a href=\"catalogue/tipping-the-velvet_999/index.html\" title=\"Tipping the Velvet\">Tipping the Velvet</a></h3>\n",
      "<div class=\"product_price\">\n",
      "<p class=\"price_color\">Â£53.74</p>\n",
      "<p class=\"instock availability\">\n",
      "<i class=\"icon-ok\"></i>\n",
      "    \n",
      "        In stock\n",
      "    \n",
      "</p>\n",
      "<form>\n",
      "<button class=\"btn btn-primary btn-block\" data-loading-text=\"Adding...\" type=\"submit\">Add to basket</button>\n",
      "</form>\n",
      "</div>\n",
      "</article>\n",
      "</li>\n"
     ]
    }
   ],
   "source": [
    "books = soup.find_all(name = \"li\", class_ = \"col-xs-6 col-sm-4 col-md-3 col-lg-3\")\n",
    "print(len(books))\n",
    "print(books[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c71cc98-a7ad-4c55-823a-d782889e0d37",
   "metadata": {},
   "source": [
    "### Get first book meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8f32e767-de83-454e-be68-04f237cbb6bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a href=\"catalogue/tipping-the-velvet_999/index.html\"><img alt=\"Tipping the Velvet\" class=\"thumbnail\" src=\"media/cache/26/0c/260c6ae16bce31c8f8c95daddd9f4a1c.jpg\"/></a>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Search for hyperlink tag\n",
    "book_one_anchor = books[1].findChild(\"a\")\n",
    "book_one_anchor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "de55af39-2c37-4fa9-854a-ca0529d0c445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'catalogue/tipping-the-velvet_999/index.html'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract book detail page end point link\n",
    "book_one_url = book_one_anchor.get(\"href\")\n",
    "book_one_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2c1bd54e-061b-4968-8e21-ee7d7e48e065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://books.toscrape.com/catalogue/tipping-the-velvet_999/index.html'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_one_url = urljoin(base_url, book_one_url)\n",
    "book_one_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72eb25b-f218-48e6-9702-eb427d6815f9",
   "metadata": {},
   "source": [
    "### Get first book HTML code from link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "78db5cfc-933f-4161-bef8-ea9fad68a742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract details webpage html data\n",
    "the_book_one_page = requests.get(book_one_url)\n",
    "#print(bs(the_book_one_page.content[6000:len(the_book_one_page.content)], 'html.parser').prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5b473e77-6db1-47c7-8e4a-76546433aeaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tipping the Velvet'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_one_soup = bs(markup = the_book_one_page.content)\n",
    "title = book_one_soup.find(\"h1\")\n",
    "title.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "49bcd135-dc24-4022-9165-81830e94cc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_one_table = book_one_soup.find_all(\"tr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9ab7f20b-61e5-4ea6-a0f1-b8c1dff25623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tr>\n",
      "<th>UPC</th><td>90fa61229261140a</td>\n",
      "</tr>, <tr>\n",
      "<th>Product Type</th><td>Books</td>\n",
      "</tr>, <tr>\n",
      "<th>Price (excl. tax)</th><td>Â£53.74</td>\n",
      "</tr>, <tr>\n",
      "<th>Price (incl. tax)</th><td>Â£53.74</td>\n",
      "</tr>, <tr>\n",
      "<th>Tax</th><td>Â£0.00</td>\n",
      "</tr>, <tr>\n",
      "<th>Availability</th>\n",
      "<td>In stock (20 available)</td>\n",
      "</tr>, <tr>\n",
      "<th>Number of reviews</th>\n",
      "<td>0</td>\n",
      "</tr>]\n",
      "\n",
      "<tr>\n",
      "<th>UPC</th><td>90fa61229261140a</td>\n",
      "</tr>\n",
      "\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print(book_one_table, end = \"\\n\\n\")\n",
    "print(book_one_table[0], end = \"\\n\\n\") # Key Value Pair\n",
    "print(len(book_one_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "663c39f4-165f-4d74-bdc5-7290d1713063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Title': <h1>Tipping the Velvet</h1>,\n",
       " 'UPC': '90fa61229261140a',\n",
       " 'Product Type': 'Books',\n",
       " 'Price (excl. tax)': 'Â£53.74',\n",
       " 'Price (incl. tax)': 'Â£53.74',\n",
       " 'Tax': 'Â£0.00',\n",
       " 'Availability': 'In stock (20 available)',\n",
       " 'Number of reviews': '0'}"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract data from HTML and add it to dictionary\n",
    "book_one_dict = {\n",
    "    \"Title\" : title\n",
    "}\n",
    "for book in book_one_table:\n",
    "    key = book.find(\"th\").text\n",
    "    value = book.find(\"td\").text\n",
    "    book_one_dict[key] = value\n",
    "\n",
    "book_one_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced23d40-949b-47bb-9173-3e44f114a294",
   "metadata": {},
   "source": [
    "### Create a function to get HTML code from link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "5d467a88-fc58-4c94-b32d-6f350b26c344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encapsulate all of the above code in a single function\n",
    "# find(), find_all(), select(), select_one()\n",
    "def scrape_book(book_url: str):\n",
    "    book_page = requests.get(book_url)\n",
    "    book_soup = bs(book_page.content)\n",
    "\n",
    "    # store data in dict\n",
    "    book_dict = {}\n",
    "\n",
    "    image = book_soup.find(name = \"div\", class_ = \"item active\").findChild(\"img\").get(\"src\")\n",
    "    title = book_soup.find(\"h1\").text\n",
    "    description = book_soup.find(\"p\").text\n",
    "    book_dict[\"title\"] = title\n",
    "    book_dict[\"image\"] = urljoin(url, image)\n",
    "    # book_dict[\"description\"] = description\n",
    "\n",
    "    book_table_data = book_soup.find_all(\"tr\")\n",
    "\n",
    "    # for product info iterate and get all key-value pairs\n",
    "    for book in book_table_data:\n",
    "        key = book.find(\"th\").text\n",
    "        value = book.find(\"td\").text\n",
    "\n",
    "        book_dict[key] = value\n",
    "\n",
    "    return book_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "ca01b6b6-6106-4839-9e07-b8acf646a01a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'A Light in the Attic',\n",
       " 'image': 'https://books.toscrape.com/media/cache/fe/72/fe72f0532301ec28892ae79a629a293c.jpg',\n",
       " 'UPC': 'a897fe39b1053632',\n",
       " 'Product Type': 'Books',\n",
       " 'Price (excl. tax)': 'Â£51.77',\n",
       " 'Price (incl. tax)': 'Â£51.77',\n",
       " 'Tax': 'Â£0.00',\n",
       " 'Availability': 'In stock (22 available)',\n",
       " 'Number of reviews': '0'}"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the method with dummy url\n",
    "scrape_book(\"http://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e5571f-e136-4ae7-b1c3-1c836d675041",
   "metadata": {},
   "source": [
    "### Create a function to scrape the entire webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "e6bab72d-4f2b-4ccd-9482-f45af4996aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_list = []\n",
    "def scrape_page(base_url: str):\n",
    "    page = requests.get(base_url)\n",
    "    page_soup = bs(page.content)\n",
    "    \n",
    "    books = page_soup.find_all(name = \"li\", class_ = \"col-xs-6 col-sm-4 col-md-3 col-lg-3\")\n",
    "\n",
    "    for i in range(len(books)):\n",
    "        relative_path = books[i].findChild(\"a\").get(\"href\") # its relative path because the full url is not provided\n",
    "        book_url = urljoin(base_url, relative_path)\n",
    "        book_data = scrape_book(book_url)\n",
    "        book_list.append(book_data)\n",
    "        print(f\"Fetched {i + 1}/{len(books)}\")\n",
    "\n",
    "    next_page_url = page_soup.find(name = \"li\", class_ = \"next\").findChild(\"a\").get(\"href\")\t\n",
    "\n",
    "\n",
    "    # Wait for 1 seconds before making next call\n",
    "    time.sleep(1) \n",
    "\n",
    "    try:\n",
    "        # Recursive call to continuoulsy fetch items from next page until next page doesnt exist\n",
    "        scrape_page(urljoin(base_url, next_page_url))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "345635ad-b177-4cfb-b745-48728d2914f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 1/20\n",
      "Fetched 2/20\n",
      "Fetched 3/20\n",
      "Fetched 4/20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[250], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# fetch all books from all pages\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mscrape_page\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp://books.toscrape.com/index.html\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mlen\u001b[39m(book_list)\n",
      "Cell \u001b[0;32mIn[249], line 11\u001b[0m, in \u001b[0;36mscrape_page\u001b[0;34m(base_url)\u001b[0m\n\u001b[1;32m      9\u001b[0m relative_path \u001b[38;5;241m=\u001b[39m books[i]\u001b[38;5;241m.\u001b[39mfindChild(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhref\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m# its relative path because the full url is not provided\u001b[39;00m\n\u001b[1;32m     10\u001b[0m book_url \u001b[38;5;241m=\u001b[39m urljoin(base_url, relative_path)\n\u001b[0;32m---> 11\u001b[0m book_data \u001b[38;5;241m=\u001b[39m \u001b[43mscrape_book\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbook_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m book_list\u001b[38;5;241m.\u001b[39mappend(book_data)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFetched \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(books)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[219], line 4\u001b[0m, in \u001b[0;36mscrape_book\u001b[0;34m(book_url)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscrape_book\u001b[39m(book_url: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m----> 4\u001b[0m     book_page \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbook_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     book_soup \u001b[38;5;241m=\u001b[39m bs(book_page\u001b[38;5;241m.\u001b[39mcontent)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# store data in dict\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.1.6_1/libexec/lib/python3.12/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.1.6_1/libexec/lib/python3.12/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.1.6_1/libexec/lib/python3.12/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.1.6_1/libexec/lib/python3.12/site-packages/requests/sessions.py:747\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    744\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    746\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[0;32m--> 747\u001b[0m     \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\n\u001b[1;32m    749\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.1.6_1/libexec/lib/python3.12/site-packages/requests/models.py:899\u001b[0m, in \u001b[0;36mResponse.content\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    898\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 899\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCONTENT_CHUNK_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content_consumed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;66;03m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[1;32m    903\u001b[0m \u001b[38;5;66;03m# since we exhausted the data.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.1.6_1/libexec/lib/python3.12/site-packages/requests/models.py:816\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    815\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 816\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    817\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    818\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.1.6_1/libexec/lib/python3.12/site-packages/urllib3/response.py:1043\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1042\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1043\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1045\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[1;32m   1046\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.1.6_1/libexec/lib/python3.12/site-packages/urllib3/response.py:935\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    932\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m amt:\n\u001b[1;32m    933\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer\u001b[38;5;241m.\u001b[39mget(amt)\n\u001b[0;32m--> 935\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    937\u001b[0m flush_decoder \u001b[38;5;241m=\u001b[39m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data)\n\u001b[1;32m    939\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.1.6_1/libexec/lib/python3.12/site-packages/urllib3/response.py:862\u001b[0m, in \u001b[0;36mHTTPResponse._raw_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    859\u001b[0m fp_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    861\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error_catcher():\n\u001b[0;32m--> 862\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         \u001b[38;5;66;03m# Close the connection when no data is returned\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.1.6_1/libexec/lib/python3.12/site-packages/urllib3/response.py:845\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    842\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1()\n\u001b[1;32m    843\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    844\u001b[0m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[0;32m--> 845\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:479\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[1;32m    478\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[0;32m--> 479\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    482\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/socket.py:707\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 707\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    708\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    709\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# fetch all books from all pages\n",
    "scrape_page('http://books.toscrape.com/index.html')\n",
    "len(book_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019b2332-e9ec-4d54-92b3-461c2cf5d514",
   "metadata": {},
   "source": [
    "### Format unstructred data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "c7c9ed09-f682-493d-a69c-65f745e75f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'A Light in the Attic',\n",
       " 'image': 'https://books.toscrape.com/media/cache/fe/72/fe72f0532301ec28892ae79a629a293c.jpg',\n",
       " 'UPC': 'a897fe39b1053632',\n",
       " 'Product Type': 'Books',\n",
       " 'Price (excl. tax)': 'Â£51.77',\n",
       " 'Price (incl. tax)': 'Â£51.77',\n",
       " 'Tax': 'Â£0.00',\n",
       " 'Availability': 'In stock (22 available)',\n",
       " 'Number of reviews': '0'}"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "29cf1586-91f8-4fa6-84b3-700047f78993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'A Light in the Attic',\n",
       "  'image': 'https://books.toscrape.com/media/cache/fe/72/fe72f0532301ec28892ae79a629a293c.jpg',\n",
       "  'UPC': 'a897fe39b1053632',\n",
       "  'Product Type': 'Books',\n",
       "  'Price (excl. tax)': 'Â£51.77',\n",
       "  'Price (incl. tax)': 'Â£51.77',\n",
       "  'Tax': 0.0,\n",
       "  'Availability': 'In stock',\n",
       "  'Number of reviews': 0.0,\n",
       "  'Quantity': 22,\n",
       "  'IsAvailable': True},\n",
       " {'title': 'Tipping the Velvet',\n",
       "  'image': 'https://books.toscrape.com/media/cache/08/e9/08e94f3731d7d6b760dfbfbc02ca5c62.jpg',\n",
       "  'UPC': '90fa61229261140a',\n",
       "  'Product Type': 'Books',\n",
       "  'Price (excl. tax)': 'Â£53.74',\n",
       "  'Price (incl. tax)': 'Â£53.74',\n",
       "  'Tax': 0.0,\n",
       "  'Availability': 'In stock',\n",
       "  'Number of reviews': 0.0,\n",
       "  'Quantity': 20,\n",
       "  'IsAvailable': True},\n",
       " {'title': 'Soumission',\n",
       "  'image': 'https://books.toscrape.com/media/cache/ee/cf/eecfe998905e455df12064dba399c075.jpg',\n",
       "  'UPC': '6957f44c3847a760',\n",
       "  'Product Type': 'Books',\n",
       "  'Price (excl. tax)': 'Â£50.10',\n",
       "  'Price (incl. tax)': 'Â£50.10',\n",
       "  'Tax': 0.0,\n",
       "  'Availability': 'In stock',\n",
       "  'Number of reviews': 0.0,\n",
       "  'Quantity': 20,\n",
       "  'IsAvailable': True}]"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fix(item: dict):\n",
    "    if item.get(\"Price (excl. tax)\") is type(str):\n",
    "        price = float(item[\"Price (excl. tax)\"][1:])\n",
    "        item[\"Price\"] = price\n",
    "        item.pop(\"Price (excl. tax)\")\n",
    "        if item[\"Price (incl. tax)\"] in item:\n",
    "            item.pop(\"Price (incl. tax)\")\n",
    "        \n",
    "\n",
    "    tax = float(item[\"Tax\"][1:])\n",
    "    item[\"Tax\"] = tax\n",
    "\n",
    "    stuff = item[\"Availability\"].split(\"(\")\n",
    "    availability = stuff[0].strip()\n",
    "    quantity = int(stuff[1].split(\" \")[0])\n",
    "    is_available = True if quantity > 0 else False\n",
    "    item[\"Availability\"] = availability\n",
    "    item[\"Quantity\"] = quantity\n",
    "    item[\"IsAvailable\"] = is_available\n",
    "\n",
    "    item[\"Number of reviews\"] = float(item[\"Number of reviews\"])\n",
    "\n",
    "    return item\n",
    "    \n",
    "formatted_books_list = list(map(lambda x : fix(x), book_list))\n",
    "formatted_books_list[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc27da2-0e89-4234-84b6-d3ab9af75003",
   "metadata": {},
   "source": [
    "### Export all books to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "bf194a97-1a9c-410e-ad9c-588ba4739d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dict_to_csv():\n",
    "    # Using \"with\" to open a file automatically handles closing file manager\n",
    "    with open('all_books.csv','w') as f:\n",
    "        # w = csv.writer(sys.stderr) # see whats being generated\n",
    "        w = csv.writer(f)\n",
    "        w.writerow(book.keys())\n",
    "        for book in book_list:\n",
    "            w.writerow(book.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1ec65e-4fe2-4437-ae6d-419b51591c78",
   "metadata": {},
   "source": [
    "### Export all books to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "23b0e59f-0b17-445c-b7b5-ab661850a8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dict_to_json():\n",
    "    # Convert and write JSON object to file\n",
    "    with open(\"all_books.json\", \"w\") as outfile: \n",
    "        json.dump(book_list, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0737863c-47cf-416c-9cb9-2b413ef1cd53",
   "metadata": {},
   "source": [
    "### Export all books to text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "71c0464b-e47a-4d23-9388-40cebbe8a232",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dict_to_textfile():\n",
    "    with open('all_books.txt', 'w') as convert_file: \n",
    "     convert_file.write(json.dumps(book_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7943db37-3ad0-4087-81ae-8ec684a09c8d",
   "metadata": {},
   "source": [
    "### Download Images of all books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "3916dcba-fee1-4879-85e7-803ad4af2972",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_images():\n",
    "    image_url_list = list(map(lambda x : x[\"image\"], book_list))\n",
    "    \n",
    "    for i in range(len(image_url_list)):\n",
    "        img_data = requests.get(image_url_list[i])\n",
    "        \n",
    "        if img_data.status_code != 200:\n",
    "            print(f\"Failed to download {image_url_list[i]} with error {book_list.status_code}\")\n",
    "            continue\n",
    "            \n",
    "        filename = image_url_list[i].split('/')[-1]\n",
    "\n",
    "        img_dir = \"book_images\"\n",
    "        \n",
    "        if img_dir not in os.listdir(os.curdir):\n",
    "            os.mkdir(img_dir)\n",
    "        \n",
    "        with open(f\"{img_dir}/{filename}\", 'wb') as f:\n",
    "            f.write(img_data.content)\n",
    "        \n",
    "        print(f\"Downloaded image {i + 1}/{len(image_url_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "8caa2d07-5adc-4bd3-85b8-28fb6a1b5e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 1/20\n",
      "Downloaded 2/20\n",
      "Downloaded 3/20\n",
      "Downloaded 4/20\n",
      "Downloaded 5/20\n",
      "Downloaded 6/20\n",
      "Downloaded 7/20\n",
      "Downloaded 8/20\n",
      "Downloaded 9/20\n",
      "Downloaded 10/20\n",
      "Downloaded 11/20\n",
      "Downloaded 12/20\n",
      "Downloaded 13/20\n",
      "Downloaded 14/20\n",
      "Downloaded 15/20\n",
      "Downloaded 16/20\n",
      "Downloaded 17/20\n",
      "Downloaded 18/20\n",
      "Downloaded 19/20\n",
      "Downloaded 20/20\n"
     ]
    }
   ],
   "source": [
    "download_images()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
